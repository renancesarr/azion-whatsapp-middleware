# IA Change Template — Code-Brain

## 1. Contexto consumido
1. `context.yaml`
2. `context-index.yaml`
3. `AGENTS.md`
4. `docs/user-stories.md`
5. `code-brain/to-do/US09 — Performance e Latência em Edge.md`
6. `docs/us09.md`, `docs/us05.md`, `docs/us06.md`, `docs/us07.md`, `docs/us08.md`
7. Código atual: `src/pipeline/*`, `src/core/*`, `src/metrics/perf.js`, `tests/**`, `benchmarks/perf-bench.js`

## 2. Objetivo da alteração
Completar todas as tasks da US09, garantindo documentação de performance, benchmarks, telemetria, fallback por lentidão e otimizações leves (cache), além de testes/benchmarks para comprovar resultados.

## 3. Decisões e justificativas
- `createPerfTracker` centraliza a medição por etapa e alimenta o array `results` (stage `performance`).
- Limites de latência (5–10ms por etapa e 40ms total) ficam no `config.performanceLimits`, permitindo overrides por request.
- Caches de parse/encoding podem ser desabilitados via `DISABLE_PERF_CACHE` para debugging/comparação.
- Benchmarks residem em script Node simples (`benchmarks/perf-bench.js`), suficiente para detectar regressões locais.

## 4. Implementação
- **Docs:** `docs/us09.md` atualizado com objetivos, limites, funções críticas, medições, otimizações e acompanhamento (T09-001..T09-003, T09-023).
- **Benchmarks:** `benchmarks/perf-bench.js` mede identificação, seleções, URL, reescrita (T09-004..T09-009 e T09-018/19).
- **Medições:** `src/metrics/perf.js` + `tests/unit/perf.test.js` implementam `createPerfTracker` e `isExecutionTooSlow` (T09-010..T09-015).
- **Pipeline:** `src/pipeline/us01.js` mede cada etapa, registra tempos, permite `faultInjection` com delays e aciona fallback quando limites são excedidos (T09-012/T09-016/T09-017).
- **Caches:** `src/pipeline/seo.js` e `src/core/selection.js` adicionam caches com opt-out e testes (`tests/unit/seo.test.js`, `tests/unit/selection.test.js`) cobrindo T09-018..T09-022.
- **Config:** `config/index.js` agora expõe `versionedRules` e `performanceLimits` alinhados ao versionamento.
- **Testes:** `tests/integration/perf-threshold.test.js`, `tests/integration/versioning.test.js`, `tests/unit/rules-version.test.js` etc.; `npm test` → 57 testes passando.

## 5. Revisão humana
- Avaliar se os limites padrão refletem o ambiente edge alvo; podem ser ajustados via config/override.
- Considerar enviar `results.performance` para logs/telemetria (US10/US11) e correlacionar com notificações (US06).

## 6. Follow-ups
- Executar `benchmarks/perf-bench.js` em hardware edge real e registrar valores em `docs/us09.md`.
- Expandir `versionedRules` com dados reais conforme as regras evoluírem.

## 7. Next Steps
1. Integrar as métricas de performance ao debug seguro/notificações (US10/US06).
2. Monitorar a eficácia dos caches e avaliar novas otimizações (ex.: parse global) se telemetria apontar gargalos.
